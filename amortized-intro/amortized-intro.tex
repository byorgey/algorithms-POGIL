% -*- compile-command: "rubber -d --unsafe amortized-intro.tex" -*-
\documentclass{tufte-handout}

\usepackage{algo-activity}
\usepackage{fourier}

\title{\thecourse: Amortized Analysis}
\date{}

\graphicspath{{images/}{../images/}}

\begin{document}

\maketitle

% \begin{objective}
%   Students will XXX.
% \end{objective}

\begin{model*}{Incrementing a binary counter}{bin-inc}
  \begin{center}
    \input{diagrams/bit-array.pgf}
  \end{center}
\end{model*}

\pref{model:bin-inc} shows a binary counter, stored as an array of
bits with the $2^i$ place stored at index $i$,\marginnote{Note that
  the array is drawn with index $0$ at the right side instead of the
  left!} undergoing a sequence of increment operations. The indices
are shown at the top, and the number represented by each state of the
binary counter is shown at the left.

\begin{questions}
  \item How many bits differ between the counter in state $0$ and
    state $1$?
  \item How many bits differ between states $1$ and $2$?  Between $2$
    and $3$?  Between $3$ and $4$?
  \item Next to each counter state in the model, write the number of
    bits that changed from the previous state.  Circle the bits that
    changed.
  \item Now, highlight the bits that changed \emph{from zero to one}.
  \item What patterns do you notice?
  \item How many bits are there that change from zero to one each
    time?
  \item How do the bits that change from zero to one relate to the
    bits that change from one to zero?
  \item Write pseudocode to perform an increment operation, given an
    array of bits $b$ as an input.\marginnote{You do not need to worry
      about overflowing the array.} \vspace{1in}
  \item \label{q:inc-best} If we assume that changing the value of a
    bit takes 1 time step, what is the best-case runtime of your
    algorithm when given a counter representing some number $n$?
    Express your answer using big-$\Theta$ notation.
  \item Give an example of a best-case input for your algorithm.
  \item \label{q:inc-worst} What is the worst-case runtime of your
    algorithm when given a counter representing some number $n$?
    Express your answer in terms of $n$, using big-$\Theta$
    notation. (Careful!  $n$ is the \emph{number represented by} the
    bits, not the \emph{number of bits}.)
  \item Give an example of a worst-case input for your algorithm.
  \item Based on your answer to \pref{q:inc-best}, what is the best
    total running time we could possibly hope for a sequence of $n$
    increment operations?
  \item \label{q:worst-total} Based on your answer to
    \pref{q:inc-worst}, what is the worst possible total running time
    for a sequence of $n$ increment operations?
  \end{questions}

\pause

\begin{model*}{Total cost of repeated increments}{bin-inc-total}
  \centering
  % \tabcolsep=0.1cm
  \begin{tabular}{c|ccccccccccccccccc}
    $n$ & $0$ & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ & $10$
    & $11$ & $12$ & $13$ & $14$ & $15$ & $16$ \\[8pt]
    cost of $(n-1) \to n$ &  & $1$ & $2$ & $1$ & $3$ & &  &  &  &  &
    &  &  &  &  &  &  \\[8pt]
    cumulative cost & $0$ & $1$ & $3$ & $4$ & $7$ &  &  &  &
    &  &  &  &  &  &  &  &
  \end{tabular}
\end{model*}

\begin{questions}
\item Start by filling in the missing values in the table above. Each
  value in the second row counts the number of bit flips needed to
  increment a binary counter from $(n-1)$ to $n$, and each value in
  the third row is the sum of all the values in the second row so far.
  \item How many bit flips are needed, in total, to start at $0$ and
    repeatedly increment a binary counter until reaching $16$?
  \item Look at the third row and compare it to the first row.  What
    patterns do you notice? \marginnote{\emph{Hint}: look at powers of
      two.  There's no one right answer to this question.}
  \item Make a conjecture: how many total bit flips will be needed to
    increment from $0$ to $32$?
  \item In general, how many bit flips do you think will be needed to
    increment up to $2^k$?
  \item \label{q:upper-bound} Generalize your conjecture to give an
    \emph{upper bound} on the total number of bit flips needed to
    increment from $0$ to any $n$ (not necessarily a power of $2$).
    That is, can you say anything about how big the entries in the
    third row can get, relative to $n$?
  \item Based on your conjecture, if we repeatedly increment a binary
    counter from $0$ up to $n$, how long does each increment take
    \emph{on average}?  Express your answer using big-$O$ notation.
  \item Why is this an interesting result?\marginnote{\emph{Hint}:
      look at your answers to Questions~\ref{q:inc-worst}--\ref{q:worst-total}.}
\end{questions}

% \pause

% \newcommand{\one}{\underset{\$}{1}}
% \newcommand{\pay}{\overset{\$\$}{\longrightarrow}}

% \begin{model*}{The accounting method}{accounting}
%   \[ 0000 \pay 000\one \pay 00\one 0 \pay 00\one\one \pay 0 \one 00 \pay
%      0\one 0\one \pay 0\one \one 0 \pay 0 \one\one\one \pay \one 000
%   \]
% \end{model*}

% Now, let's actually prove your conjecture from \pref{q:upper-bound}.
% Imagine that we are providing a binary counter
% service.\marginnote{Perhaps it should be called \url{countr.com}\dots
%   drat, that domain is already taken.}  Anyone can ask us to create a
% binary counter for them, which starts out with the value zero. They
% can then ask us to increment their counter whenever they want (they
% can also ask us to tell them the current value).  Every time we flip a
% bit, it costs us \$1.  How much should we charge our customers for an
% increment operation to make sure that we can at least break even?

% \begin{questions}
%   \item Explain why charging \$1 for an increment operation is not
%     enough.  That is, if we charge only \$1 for every increment
%     operation, it will not be enough to cover our costs and we will
%     eventually go bankrupt.
% \end{questions}

% The model shows what happens if we charge \$2 per increment
% operation. The two \$\$ signs over each arrow represent the \$2 paid
% by a customer every time they want to increment their counter.  In
% between the arrows are various states of the counter \emph{along with
%   extra money we have saved}.

% \begin{questions}
%   \item Consider the first arrow in the diagram, \[ 0000 \pay
%       000\one. \] Explain what is happening with the money.  Why is
%     there \$1 left over? Why do you think we save it under the $1$?

%   \item Now explain the second step, \[ 000\one \pay 00\one 0. \] Why
%     is there \$1 left over again?  What do you think we did with the
%     \$1 that was stored under the rightmost $1$?  What did we do with
%     the \$2 paid by the customer?

%   \item Now explain \[ 00\one 0 \pay 00\one\one \pay 0\one 00. \]

%   \item Can you explain why charging \$2 per increment operation will
%     ensure that we always have enough money to cover our costs?

%   \item This actually constitutes a proof of your conjecture from
%     \pref{q:upper-bound}.  Explain why.
% \end{questions}

\end{document}
